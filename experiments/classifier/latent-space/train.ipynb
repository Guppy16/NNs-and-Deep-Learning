{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise latent space\n",
    "\n",
    "The aim of this notebook is to replicate a figure from the lecture notes of _Cambridge Engineering-Deep Learning for Computer Vision_. The task is binary classification with a 3 node hidden layer. This hidden layer is visualised in 3D space, which showed that the action of learning _pushed_ the weights into corners of the cube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[digit_classifier] [INFO] Added console handler\n",
      "[digit_classifier] [INFO] Torch device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Relative import hack\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "# Setup logging\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.animation as ani\n",
    "from matplotlib import cm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from digit_classifier import base, DigitClassifier, DEVICE, Metrics, DigitClassifierConfig, train_test_datasets, train_val_dataset_split\n",
    "import logging\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base() # Set seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "config = DigitClassifierConfig(\n",
    "\tsizes=[784, 10, 3, 10],\n",
    "\tlearning_rate=1,\n",
    "  device=DEVICE,\n",
    "  loss = nn.MSELoss(reduction='mean'),\n",
    "  mini_batch = 20,\n",
    ")\n",
    "\n",
    "model_dir = Path(\"../../resources/model/latent_space/\")\n",
    "metrics_dir = model_dir / 'metrics.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[digit_classifier] [INFO] Train size: 60000\n",
      "[digit_classifier] [INFO] Test size: 10000\n",
      "[digit_classifier] [INFO] Train set: 50000\n",
      "[digit_classifier] [INFO] Valid set: 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the labels of the training set\n",
    "train_set = train_val_dataset_split(train_test_datasets()[0])[0]\n",
    "labels = [train_set[i][1] for i in range(len(train_set))]\n",
    "labels = np.array(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSPECT_LAYER = 1  # Which layer to inspect. Set this to K - 1\n",
    "\n",
    "# Variable to store the latent space output and classifier label\n",
    "# Shape: (epoch, training example, latent space)\n",
    "latent_label = []\n",
    "\n",
    "latent_dataloader = torch.utils.data.DataLoader(train_set, batch_size=1000, shuffle=False,num_workers=2, drop_last=False)\n",
    "\n",
    "@torch.no_grad()\n",
    "def func(dc: DigitClassifier, **func_kwargs):\n",
    "  \"\"\"Keep track of the latent space output\n",
    "\n",
    "  Args:\n",
    "    dc: DigitClassifier\n",
    "    ll: np array to store the outputs\n",
    "\n",
    "  After each batch/epoch, evaluate on the training set (with no grad)\n",
    "  for each data point\n",
    "  - run a forward pass\n",
    "  - keep track of the latent space, and the output\n",
    "  \"\"\"\n",
    "  ll: list = func_kwargs['ll']\n",
    "\n",
    "  dc.eval()\n",
    "  # Increment ll axis 0\n",
    "  ll.append([])\n",
    "  # ll = np.append(ll, np.zeros((1, 1, config.sizes[1] + 1)), axis=0)\n",
    "  for x, y in latent_dataloader:\n",
    "    for layer_idx, layer in enumerate(dc.linears):\n",
    "      x = layer(x)\n",
    "      x = dc.act_fn(x)\n",
    "      if layer_idx == INSPECT_LAYER:\n",
    "        break\n",
    "    latent_space = x.detach().numpy()\n",
    "    # latent_space = np.append(latent_space, y.cpu().numpy()[:,None], axis=1)\n",
    "    ll[-1] += latent_space.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[digit_classifier] [INFO] Train size: 60000\n",
      "[digit_classifier] [INFO] Test size: 10000\n",
      "[digit_classifier] [INFO] Train set: 50000\n",
      "[digit_classifier] [INFO] Valid set: 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DigitClassifier(\n",
       "  (act_fn): Sigmoid()\n",
       "  (linears): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (1): Linear(in_features=10, out_features=3, bias=True)\n",
       "    (2): Linear(in_features=3, out_features=10, bias=True)\n",
       "  )\n",
       "  (loss_module): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DigitClassifier(config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[digit_classifier] [INFO] Epoch: 0: 1149 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 1: 2076 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 2: 2773 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 3: 4278 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 4: 4718 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 5: 5290 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 6: 5684 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 7: 5885 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 8: 5840 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 9: 5922 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 10: 6188 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 11: 6262 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 12: 6550 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 13: 6744 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 14: 7326 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 15: 7598 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 16: 7733 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 17: 8041 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 18: 8187 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 19: 8243 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 20: 8180 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 21: 8341 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 22: 8435 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 23: 8509 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 24: 8508 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 25: 8583 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 26: 8586 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 27: 8677 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 28: 8732 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 29: 8742 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 30: 8768 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 31: 8752 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 32: 8796 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 33: 8817 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 34: 8838 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 35: 8838 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 36: 8886 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 37: 8898 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 38: 8880 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 39: 8927 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 40: 8917 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 41: 8889 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 42: 8901 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 43: 8938 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 44: 8939 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 45: 8927 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 46: 8958 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 47: 8945 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 48: 8942 / 10000\n",
      "[digit_classifier] [INFO] Epoch: 49: 8938 / 10000\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "metrics = Metrics()\n",
    "model.train_loop(num_epochs=epochs, metrics=metrics, func=func, ll=latent_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('../../resources/model/latent_space/model.tar'),\n",
       " PosixPath('../../resources/model/latent_space/config.pkl'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model\n",
    "model.save_model(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50000, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent_label = np.array(latent_label)\n",
    "latent_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array and save\n",
    "f = model_dir / f'latents-{epochs}.npy'\n",
    "np.save(f, latent_label)\n",
    "f = model_dir / f'labels.npy'\n",
    "np.save(f, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
