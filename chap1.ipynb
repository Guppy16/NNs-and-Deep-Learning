{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a digit classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from ignite.metrics import ConfusionMatrix\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Set device\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seeds\n",
    "seed = 16\n",
    "torch.manual_seed(seed) # Set CPU seed\n",
    "# Set GPU seeds\n",
    "if torch.cuda.is_available():\n",
    "  torch.cuda.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "# Make torch algos deterministic\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "# Create a rng\n",
    "rng = torch.Generator().manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 50000\n",
      "Validation size: 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = \"./resources/data/\"\n",
    "val_size = 10000\n",
    "\n",
    "# Transform data \n",
    "t = transforms.Compose([\n",
    "  transforms.PILToTensor(),\n",
    "  transforms.ConvertImageDtype(torch.float),\n",
    "  torch.flatten,\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(root=root, train=True, download=True, transform=t)\n",
    "train_set, val_set = torch.utils.data.random_split(train_data, [len(train_data) - val_size, val_size], generator=rng)\n",
    "print(f\"Train size: {len(train_set)}\\nValidation size: {len(val_set)}\")\n",
    "train_set[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "model_params = dict(\n",
    "\tsizes=[784, 30, 10],\n",
    "\tlearning_rate=3,\n",
    "  device=device,\n",
    "  loss = nn.MSELoss(reduction='mean')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DigitClassifier(\n",
       "  (act_fn): Sigmoid()\n",
       "  (linears): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=30, bias=True)\n",
       "    (1): Linear(in_features=30, out_features=10, bias=True)\n",
       "  )\n",
       "  (loss_module): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DigitClassifier(nn.Module):\n",
    "  def __init__(self, sizes: tuple[int], learning_rate: float, device: torch.device, loss: nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      sizes: size of each layer\n",
    "      learning_rate: learning rate when optimising parameters\n",
    "      device: torch device type (cuda or cpu)\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self.num_layers = len(sizes)\n",
    "    self.act_fn = nn.Sigmoid()\n",
    "    # Define linear weights between each layer:\n",
    "    self.linears = nn.ModuleList(\n",
    "        [nn.Linear(ip, op) for ip, op in zip(sizes, sizes[1:])]\n",
    "    )\n",
    "\n",
    "    self.num_classes = sizes[-1]\n",
    "    self.optimizer = torch.optim.SGD(self.parameters(), lr=learning_rate)\n",
    "    self.loss_module = loss\n",
    "\n",
    "    # Set device\n",
    "    self.to(device)\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\"Forward pass over all neurons\"\"\"\n",
    "    for layer in self.linears:\n",
    "      x = layer(x)\n",
    "      x = self.act_fn(x)\n",
    "    return x\n",
    "\n",
    "  def train_loop(self, train_data_loader: DataLoader, num_epochs: int = 30, val_data_loader: DataLoader = None):\n",
    "    \"\"\"Training neurons\"\"\"\n",
    "    # Set model to train mode\n",
    "    model.train()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "      for data_inputs, data_labels in train_data_loader:\n",
    "        # 1. Move input data to device\n",
    "        data_inputs = data_inputs.to(device)\n",
    "        data_labels = data_labels.to(device)\n",
    "\n",
    "        # 2. Run model on input data\n",
    "        preds = self.forward(data_inputs)\n",
    "\n",
    "        # 3. Calculate loss\n",
    "        loss = self.loss_module(\n",
    "            preds, nn.functional.one_hot(\n",
    "                data_labels, num_classes=self.num_classes).float()\n",
    "        )\n",
    "\n",
    "        # 4. Perform backpropogation\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Update parameters\n",
    "        self.optimizer.step()\n",
    "\n",
    "      # After epoch\n",
    "      # TODO: Evaluate model on train set\n",
    "      # Evaluate model on val set\n",
    "      if val_data_loader:\n",
    "        precision = self.precision(val_data_loader)\n",
    "        total = len(val_data_loader.dataset)\n",
    "        print(f\"Epoch: {epoch}: {precision*total} / {total}\")\n",
    "\n",
    "  @torch.no_grad()\n",
    "  def precision(self, data_loader: DataLoader):\n",
    "    \"\"\"Return precision of data\"\"\"\n",
    "    model.eval()\n",
    "    predicted, labels = zip(*((self.forward(ip), lbl)\n",
    "                            for ip, lbl in data_loader))\n",
    "    # Stack and reshape predictions and labels\n",
    "    predicted = torch.stack(predicted).reshape(-1, self.num_classes)\n",
    "    labels = torch.stack(labels).flatten()\n",
    "    # Use argmax to calculate predicted labels\n",
    "    predicted = predicted.argmax(-1)\n",
    "\n",
    "    # Calculate true positives\n",
    "    true_positives = (predicted == labels).sum()\n",
    "\n",
    "    return true_positives / len(labels)\n",
    "\n",
    "\n",
    "model = DigitClassifier(**model_params)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4243, 0.5256, 0.4832, 0.3969, 0.4904, 0.5011, 0.4557, 0.4306, 0.5671,\n",
       "        0.4518], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check forward model is working\n",
    "model.forward(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0: 9190.0 / 10000\n",
      "Epoch: 1: 9335.0 / 10000\n",
      "Epoch: 2: 9371.0 / 10000\n",
      "Epoch: 3: 9416.0 / 10000\n",
      "Epoch: 4: 9463.0 / 10000\n",
      "Epoch: 5: 9470.0 / 10000\n",
      "Epoch: 6: 9484.0 / 10000\n",
      "Epoch: 7: 9521.0 / 10000\n",
      "Epoch: 8: 9513.0 / 10000\n",
      "Epoch: 9: 9519.0 / 10000\n",
      "Epoch: 10: 9540.0 / 10000\n",
      "Epoch: 11: 9547.0 / 10000\n",
      "Epoch: 12: 9548.0 / 10000\n",
      "Epoch: 13: 9542.0 / 10000\n",
      "Epoch: 14: 9553.0 / 10000\n",
      "Epoch: 15: 9562.0 / 10000\n",
      "Epoch: 16: 9553.0 / 10000\n",
      "Epoch: 17: 9553.0 / 10000\n",
      "Epoch: 18: 9567.0 / 10000\n",
      "Epoch: 19: 9570.0 / 10000\n"
     ]
    }
   ],
   "source": [
    "mini_batch = 10\n",
    "epochs = 20\n",
    "train_dataloader = DataLoader(train_set, batch_size=mini_batch, shuffle=True, num_workers=0, drop_last=False)\n",
    "val_dataloader = DataLoader(val_set, batch_size=mini_batch, shuffle=False, num_workers=0, drop_last=False)\n",
    "model.train_loop(num_epochs=epochs, train_data_loader=train_dataloader, val_data_loader=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model parameters\n",
    "state_dict = model.state_dict()\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "model_fname = f\"resources/model/{timestr}.tar\"\n",
    "torch.save(state_dict, model_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "state_dict = torch.load(model_fname)\n",
    "model = DigitClassifier(**model_params)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9516)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model on val_set\n",
    "precision = model.precision(DataLoader(val_set, batch_size=8, shuffle=False, drop_last=False))\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chap 1 Exercise - No hidden layer\n",
    "\n",
    "Aim: Find out how well NN does without a hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DigitClassifier(\n",
       "  (act_fn): Sigmoid()\n",
       "  (linears): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=10, bias=True)\n",
       "  )\n",
       "  (loss_module): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2layer_params = dict(\n",
    "  sizes=[784, 10],\n",
    "  learning_rate=3,\n",
    "  device=device,\n",
    "  loss = nn.MSELoss(reduction='mean')\n",
    ")\n",
    "model_2layer = DigitClassifier(**model_2layer_params)\n",
    "model_2layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0: 8927.0 / 10000\n",
      "Epoch: 1: 8999.0 / 10000\n",
      "Epoch: 2: 8931.0 / 10000\n",
      "Epoch: 3: 9023.0 / 10000\n",
      "Epoch: 4: 9016.0 / 10000\n",
      "Epoch: 5: 9082.0 / 10000\n",
      "Epoch: 6: 9066.0 / 10000\n",
      "Epoch: 7: 9091.0 / 10000\n",
      "Epoch: 8: 9072.0 / 10000\n",
      "Epoch: 9: 9041.0 / 10000\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "epochs = 10\n",
    "model_2layer.train_loop(num_epochs=epochs, train_data_loader=train_dataloader, val_data_loader=val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.1\tPrecision: 0.8964999914169312\n",
      "Learning rate: 1\tPrecision: 0.9092000126838684\n",
      "Learning rate: 1.5\tPrecision: 0.9049000144004822\n",
      "Learning rate: 2\tPrecision: 0.9067000150680542\n",
      "Learning rate: 4\tPrecision: 0.9052000045776367\n"
     ]
    }
   ],
   "source": [
    "# Perform hyperparameter search over mini_batch and learning rate:\n",
    "\n",
    "learning_rates = [0.1,1,1.5,2,4]\n",
    "precisions = []\n",
    "epochs = 5\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "  m = DigitClassifier(sizes=[784,10], learning_rate=learning_rate, device=device)\n",
    "  m.train_loop(num_epochs=epochs, train_data_loader=train_dataloader)\n",
    "  precision = m.precision(DataLoader(val_set, batch_size=8))\n",
    "  print(f\"Learning rate: {learning_rate}\\tPrecision: {precision:.2f}\")\n",
    "  precisions.append(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chap 2 Exercise: Change loss module to Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_CE_params = dict(\n",
    "\tsizes=[784, 30, 10],\n",
    "\tlearning_rate=0.5,\n",
    "  device=device,\n",
    "  loss = nn.CrossEntropyLoss()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0: 9561.0 / 10000\n",
      "Epoch: 1: 9565.0 / 10000\n",
      "Epoch: 2: 9587.0 / 10000\n",
      "Epoch: 3: 9573.0 / 10000\n",
      "Epoch: 4: 9553.0 / 10000\n",
      "Epoch: 5: 9572.0 / 10000\n",
      "Epoch: 6: 9565.0 / 10000\n",
      "Epoch: 7: 9575.0 / 10000\n",
      "Epoch: 8: 9571.0 / 10000\n",
      "Epoch: 9: 9577.0 / 10000\n",
      "Epoch: 10: 9576.0 / 10000\n",
      "Epoch: 11: 9559.0 / 10000\n",
      "Epoch: 12: 9586.0 / 10000\n",
      "Epoch: 13: 9582.0 / 10000\n",
      "Epoch: 14: 9586.0 / 10000\n",
      "Epoch: 15: 9553.0 / 10000\n",
      "Epoch: 16: 9574.0 / 10000\n",
      "Epoch: 17: 9571.0 / 10000\n",
      "Epoch: 18: 9575.0 / 10000\n",
      "Epoch: 19: 9566.0 / 10000\n"
     ]
    }
   ],
   "source": [
    "model_CE = DigitClassifier(**model_CE_params)\n",
    "model.train_loop(num_epochs=epochs, train_data_loader=train_dataloader, val_data_loader=val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the CE loss shows that the NN learnt very quickly. This is obvious looking at how by Epoch 0 in CE loss, the network had effectively peaked, wheras the network with MSE loss was still learning by Epoch 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset for playground work\n",
    "idea_set, _ = torch.utils.data.random_split(val_set, [16, len(val_set) - 16], rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4, 7, 0, 2, 2, 8, 8, 4]), tensor([1, 2, 2, 8, 2, 4, 7, 8]))"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, labels = zip(*((model.forward(ip), lbl) for ip, lbl in DataLoader(idea_set, batch_size=8)))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 7, 0, 2, 2, 8, 8, 4, 1, 2, 2, 8, 2, 4, 7, 8])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = torch.stack(result).reshape(-1, 10)\n",
    "labels = torch.stack(labels).flatten()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(result.argmax(-1) == labels).sum() / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataloader.dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gf3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
